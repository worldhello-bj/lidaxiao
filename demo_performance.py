#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ä¼˜åŒ–æ¼”ç¤ºè„šæœ¬
Performance improvement demonstration script

ç”¨æ³• (Usage):
  python3 demo_performance.py           # æ ‡å‡†æ¨¡å¼æ¼”ç¤º
  python3 demo_performance.py --fast    # å¿«é€Ÿæ¨¡å¼æ¼”ç¤º
"""

import asyncio
import time
import argparse
from config import BROWSER_CONFIG


def simulate_page_operations():
    """æ¨¡æ‹Ÿé¡µé¢æ“ä½œä»¥å±•ç¤ºæ€§èƒ½å·®å¼‚"""
    from crawler import get_timing_config
    
    timing = get_timing_config()
    mode_name = "å¿«é€Ÿæ¨¡å¼" if BROWSER_CONFIG.get("fast_mode", False) else "æ ‡å‡†æ¨¡å¼"
    
    print(f"ğŸ¯ {mode_name}æ€§èƒ½æ¼”ç¤º")
    print("=" * 40)
    print(f"å½“å‰é…ç½®:")
    print(f"  â€¢ é¡µé¢åŠ è½½ç­‰å¾…: {timing['page_load_wait']}ms")
    print(f"  â€¢ åˆ†é¡µç‚¹å‡»ç­‰å¾…: {timing['pagination_wait']}ms")
    print(f"  â€¢ æ“ä½œåç­‰å¾…: {timing['post_action_wait']}ms")
    print(f"  â€¢ é¡µé¢é—´éš”: {timing['page_interval_min']}-{timing['page_interval_max']}s")
    print(f"  â€¢ ç½‘ç»œè¶…æ—¶: {timing['network_timeout']}ms")
    print()
    
    return timing


async def simulate_video_crawling(timing):
    """æ¨¡æ‹Ÿè§†é¢‘çˆ¬å–æµç¨‹"""
    total_start = time.time()
    
    print("ğŸ“‹ æ¨¡æ‹Ÿè§†é¢‘çˆ¬å–æµç¨‹:")
    
    # 1. é¡µé¢åŠ è½½
    print("  1. é¡µé¢åŠ è½½ä¸­...", end=" ", flush=True)
    start = time.time()
    await asyncio.sleep(timing["page_load_wait"] / 1000)
    duration = time.time() - start
    print(f"è€—æ—¶ {duration:.2f}s")
    
    # 2. è·å–è§†é¢‘åˆ—è¡¨
    print("  2. è·å–è§†é¢‘åˆ—è¡¨...", end=" ", flush=True)
    start = time.time()
    await asyncio.sleep(timing["post_action_wait"] / 1000)
    duration = time.time() - start
    print(f"è€—æ—¶ {duration:.2f}s")
    
    # 3. åˆ†é¡µæ“ä½œ (æ¨¡æ‹Ÿ3é¡µ)
    page_count = 3
    for page in range(2, page_count + 1):
        print(f"  3.{page-1} ç‚¹å‡»ç¬¬{page}é¡µ...", end=" ", flush=True)
        start = time.time()
        
        # åˆ†é¡µç‚¹å‡»ç­‰å¾…
        await asyncio.sleep(timing["pagination_wait"] / 1000)
        # é¡µé¢åŠ è½½ç­‰å¾…
        await asyncio.sleep(timing["post_action_wait"] / 1000)
        # é¡µé¢é—´éš”
        interval = (timing["page_interval_min"] + timing["page_interval_max"]) / 2
        await asyncio.sleep(interval)
        
        duration = time.time() - start
        print(f"è€—æ—¶ {duration:.2f}s")
    
    total_duration = time.time() - total_start
    print(f"\nğŸ“Š æ€»è€—æ—¶: {total_duration:.2f}s")
    
    return total_duration


def compare_modes():
    """æ¯”è¾ƒæ ‡å‡†æ¨¡å¼å’Œå¿«é€Ÿæ¨¡å¼çš„æ€§èƒ½"""
    print("âš¡ æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 40)
    
    # æ ‡å‡†æ¨¡å¼æ—¶é—´
    standard_times = {
        "page_load_wait": 2000,
        "pagination_wait": 1000,
        "post_action_wait": 2000,
        "page_interval_avg": 4500,  # (3000 + 6000) / 2
    }
    
    # å¿«é€Ÿæ¨¡å¼æ—¶é—´
    fast_times = {
        "page_load_wait": 500,
        "pagination_wait": 300,
        "post_action_wait": 800,
        "page_interval_avg": 1500,  # (1000 + 2000) / 2
    }
    
    # è®¡ç®—å•é¡µæ“ä½œæ—¶é—´ (ç‚¹å‡»åˆ†é¡µ + é¡µé¢åŠ è½½ + é¡µé¢é—´éš”)
    standard_per_page = (standard_times["pagination_wait"] + 
                        standard_times["post_action_wait"] + 
                        standard_times["page_interval_avg"]) / 1000
    
    fast_per_page = (fast_times["pagination_wait"] + 
                    fast_times["post_action_wait"] + 
                    fast_times["page_interval_avg"]) / 1000
    
    # è®¡ç®—3é¡µæ€»æ—¶é—´ (åˆå§‹é¡µé¢åŠ è½½ + 2æ¬¡ç¿»é¡µ)
    standard_total = (standard_times["page_load_wait"] + 
                     standard_times["post_action_wait"]) / 1000 + 2 * standard_per_page
    
    fast_total = (fast_times["page_load_wait"] + 
                 fast_times["post_action_wait"]) / 1000 + 2 * fast_per_page
    
    improvement = (standard_total - fast_total) / standard_total * 100
    
    print(f"æ ‡å‡†æ¨¡å¼é¢„è®¡æ—¶é—´: {standard_total:.1f}s")
    print(f"å¿«é€Ÿæ¨¡å¼é¢„è®¡æ—¶é—´: {fast_total:.1f}s")
    print(f"æ€§èƒ½æå‡: {improvement:.1f}%")
    print(f"æ—¶é—´èŠ‚çœ: {standard_total - fast_total:.1f}s")
    print()


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º')
    parser.add_argument('--fast', action='store_true', help='å¯ç”¨å¿«é€Ÿæ¨¡å¼')
    args = parser.parse_args()
    
    print("ğŸš€ æå¤§éœ„æŒ‡æ•°ç¨‹åºæ€§èƒ½ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 50)
    
    if args.fast:
        from crawler import enable_fast_mode
        enable_fast_mode()
        print("âœ… å·²å¯ç”¨å¿«é€Ÿæ¨¡å¼")
    else:
        print("ğŸ“‹ ä½¿ç”¨æ ‡å‡†æ¨¡å¼")
    
    print()
    
    # æ˜¾ç¤ºå¯¹æ¯”åˆ†æ
    compare_modes()
    
    # æ¨¡æ‹Ÿæ“ä½œ
    timing = simulate_page_operations()
    actual_duration = await simulate_video_crawling(timing)
    
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    if args.fast:
        print("  â€¢ å¿«é€Ÿæ¨¡å¼é€‚åˆæ—¥å¸¸ä½¿ç”¨å’Œç•Œé¢æ“ä½œ")
        print("  â€¢ æ˜¾è‘—æé«˜å“åº”é€Ÿåº¦å’Œç”¨æˆ·ä½“éªŒ")
        print("  â€¢ å‘½ä»¤è¡Œä½¿ç”¨: python3 lidaxiao.py --fast")
    else:
        print("  â€¢ æ ‡å‡†æ¨¡å¼æä¾›æœ€å¼ºçš„åæ£€æµ‹èƒ½åŠ›")
        print("  â€¢ é€‚åˆéœ€è¦ç¨³å®šæ€§çš„æ‰¹é‡æ“ä½œ")
        print("  â€¢ å¯é€šè¿‡ --fast å‚æ•°å¯ç”¨å¿«é€Ÿæ¨¡å¼")
    
    print("\nğŸ¯ å¿«é€Ÿå¯ç”¨æ–¹æ³•:")
    print("  python3 lidaxiao.py --fast        # å‘½ä»¤è¡Œå¯ç”¨")
    print("  crawler.enable_fast_mode()        # ä»£ç ä¸­å¯ç”¨")


if __name__ == "__main__":
    asyncio.run(main())